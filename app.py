import streamlit as st
import numpy as np
from PIL import Image
import tensorflow as tf
from transformers import pipeline

st.set_page_config(page_title="MiniMind â€“ L'IA expliquÃ©e", page_icon="ðŸ§ ", layout="centered")

st.title("MiniMind â€“ Lâ€™IA expliquÃ©e simplement")
st.caption("DÃ©fi AI4GOOD â€“ Nuit de lâ€™Info 2025 â€“ Ã‰quipe [ton nom]")

st.markdown("### 3 expÃ©riences pour dÃ©couvrir lâ€™IA comme un collÃ©gien !")

# ===================== 1. CHATBOT (modÃ¨le qui marche Ã  100%) =====================
st.header("1. Le petit robot qui discute")

@st.cache_resource
def get_chatbot():
    # TinyLlama = 1.1B paramÃ¨tres, ultra-rapide, 100% PyTorch â†’ marche direct sur Streamlit
    return pipeline(
        "text-generation",
        model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        torch_dtype="auto",
        device_map="auto",
        max_new_tokens=100
    )

with st.spinner("Chargement du petit robotâ€¦ (30-40 sec la premiÃ¨re fois)"):
    chatbot = get_chatbot()

if "history" not in st.session_state:
    st.session_state.history = []

question = st.text_input("Pose-lui une question :", placeholder="Salut, tu connais l'IA ?")

if question:
    with st.spinner("MiniMind rÃ©flÃ©chitâ€¦"):
        result = chatbot(f"<|system|>\nTu es MiniMind, un assistant gentil qui explique l'IA aux enfants.</|system|>\n<|user|>\n{question}</|user|>\n<|assistant|>", 
                         do_sample=True, temperature=0.7)
        reponse = result[0]["generated_text"].split("<|assistant|>")[-1].strip()
    st.session_state.history.append(("Toi", question))
    st.session_state.history.append(("MiniMind", reponse))

for sender, msg in st.session_state.history:
    if sender == "Toi":
        st.markdown(f"**Toi** : {msg}")
    else:
        st.markdown(f"**MiniMind** : {msg}")

# ===================== 2. RECONNAISSANCE D'IMAGES =====================
st.header("2. Câ€™est un chat ou un chien ?")

if "model" not in st.session_state:
    with st.spinner("Chargement du modÃ¨le photoâ€¦"):
        model = tf.keras.models.load_model("keras_model.h5")
        with open("labels.txt", "r", encoding="utf-8") as f:
            class_names = []
            for line in f:
                parts = line.strip().split(" ", 1)
                class_names.append(parts[1] if len(parts) > 1 else parts[0])
        st.session_state.model = model
        st.session_state.class_names = class_names

model = st.session_state.model
class_names = st.session_state.class_names

uploaded = st.file_uploader("Envoie une photo", type=["jpg", "jpeg", "png"])
if uploaded:
    image = Image.open(uploaded).convert("RGB").resize((224, 224))
    st.image(image, width=300)
    img_array = np.array(image) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    pred = model.predict(img_array)[0]
    idx = np.argmax(pred)
    st.success(f"Câ€™est un **{class_names[idx]}** !")
    st.progress(float(pred[idx]))
    with st.expander("DÃ©tails"):
        for name, p in zip(class_names, pred):
            st.write(f"{name} â†’ {p:.1%}")

# ===================== 3. PRÃ‰DICTEUR DE NOTES =====================
st.header("3. Combien dâ€™heures pour avoir 20/20 ?")
col1, col2 = st.columns(2)
with col1:
    etude = st.slider("Heures dâ€™Ã©tude", 0, 50, 20)
with col2:
    sommeil = st.slider("Heures de sommeil", 4, 12, 8)

note = min(20, etude * 0.3 + sommeil * 1.2 + 2)
st.metric("Note prÃ©dite", f"{note:.1f}/20")
if note >= 18:
    st.balloons()

# ===================== FIN =====================
st.success("Projet terminÃ© ! Tout fonctionne !")
st.balloons()
